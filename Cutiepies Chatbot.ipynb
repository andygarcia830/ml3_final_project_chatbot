{"cells":[{"cell_type":"markdown","metadata":{"id":"TT3HnaYONXiL"},"source":["Create and environment to use with this notebook:<br>\n","conda create -n ml3_final_project scipy scikit-image statsmodels scikit-learn pandas ipykernel tqdm keras pillow matplotlib pytorch==2.4.1 pytorch-cuda=12.4 torchinfo tensorflow=2.17 accelerate langchain pydub -c pytorch -c nvidia -c conda-forge"]},{"cell_type":"markdown","metadata":{"id":"Q1F_fDJcNXiP"},"source":["Install prerequisites uncomment and run once"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"SRPNjB1TNXiP","executionInfo":{"status":"ok","timestamp":1741025816109,"user_tz":-480,"elapsed":14,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"outputs":[],"source":["# ! pip install parler-tts\n","# ! pip install spaces\n","# ! pip install accelerate\n","# ! pip install pydub\n","# ! pip install transformers\n","# # ! pip install --upgrade protobuf\n","# ! pip install openai-whisper\n","# !pip install langchain_openai\n","# !pip install langchain_deepseek\n","# !pip install gtts"]},{"cell_type":"code","source":["# !apt install ffmpeg"],"metadata":{"id":"iQHn16wSrk1n","executionInfo":{"status":"ok","timestamp":1741025816119,"user_tz":-480,"elapsed":8,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# for Colab\n","from google.colab import drive\n","drive.mount('/content/drive')\n","data_dir = '/content/drive/MyDrive/ml3_final_project_chatbot'\n","\n","# for local\n","# data_dir = './'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fAyrx3AjXSt-","executionInfo":{"status":"ok","timestamp":1741025819546,"user_tz":-480,"elapsed":3425,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}},"outputId":"1099fb67-68f5-44f4-db13-c5b520d6dbda"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"8MDtrO-gNXiR"},"source":["Setup The LLM Part"]},{"cell_type":"markdown","source":["For Colab, store your OPENAI_API_KEY in your Secrets section"],"metadata":{"id":"lWxdr6Gta0PZ"}},{"cell_type":"code","source":["import os\n","from google.colab import userdata\n","os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"],"metadata":{"id":"Z3ySIHawaPVM","executionInfo":{"status":"ok","timestamp":1741025820769,"user_tz":-480,"elapsed":1224,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"3dzBCsqQNXiR","executionInfo":{"status":"ok","timestamp":1741025822048,"user_tz":-480,"elapsed":1277,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"outputs":[],"source":["# from langchain_deepseek import ChatDeepSeek\n","from langchain_core.prompts import PromptTemplate\n","from langchain_openai import ChatOpenAI\n","from datetime import datetime\n","import random\n","import numpy as np"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"nW1eL8JgNXiS","executionInfo":{"status":"ok","timestamp":1741025822067,"user_tz":-480,"elapsed":8,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"outputs":[],"source":["conversation_history = []\n","intro_given = False\n","active = True\n","inactive_timer = datetime.now()\n","talking = False\n","silence_counter = 0\n","voice_data=np.array([])\n","last_query = ''\n","last_response=''\n","summary = '<EMPTY>'"]},{"cell_type":"code","source":["def format_transcript(history):\n","  transcript = ''\n","  for item in history:\n","    transcript += f'Patient: {item[\"patient\"]}\\nChloe: {item[\"you\"]}\\n'\n","  if len(transcript) == 0:\n","    transcript='<EMPTY>'\n","  return transcript"],"metadata":{"id":"wrz1ZYuCIdTm","executionInfo":{"status":"ok","timestamp":1741025822069,"user_tz":-480,"elapsed":1,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"KO3zEZ7XNXiS","executionInfo":{"status":"ok","timestamp":1741025822080,"user_tz":-480,"elapsed":2,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"outputs":[],"source":["def get_response(query):\n","    global intro_given\n","    confused_messages = [\n","        \"I'm sorry, I did not understand. Can you repeat that please?\",\n","        \"Paumanhin, hindi ko maintindihan ang iyong sinabi. Maari mo bang ulitin?\",\n","        \"Sorry, I did not understand. Can you repeat that last message please?\",\n","        \"I'm sorry, I did not quite get that. Can you repeat that please?\",\n","        \"Sorry, I did not quite get that. Can you repeat that please?\",\n","        \"I'm sorry, I did not quite get that. Can you repeat please?\",\n","        \"I'm sorry, I did not get that. Can you repeat that last message please?\",\n","    ]\n","\n","\n","    if query == None:\n","        return None, status, summary, format_transcript(conversation_history)\n","\n","    template = \"\"\"Question: {question}\n","\n","    Answer: \"\"\"\n","\n","    prompt = PromptTemplate.from_template(template)\n","    # llm =ChatDeepSeek(\n","    #         model=\"deepseek-chat\",\n","    llm =ChatOpenAI(\n","            model=\"gpt-4o\",\n","            temperature=0,\n","            max_tokens=None,\n","            timeout=None,\n","            max_retries=2,\n","            # other params...\n","        )\n","    llm_chain = prompt | llm\n","    if len(conversation_history) > 20:\n","        del conversation_history[0]\n","\n","    intro_intsruction = ''\n","\n","    if not intro_given:\n","        intro_intsruction ='Introduce yourself to the patient.'\n","\n","    lang_detect = f\"what language is the following text? give a one word answer: {query}\"\n","    language = llm_chain.invoke(lang_detect).content\n","    print(f'LANGUAGE={language}')\n","    if (language.strip().lower() not in ['english', 'filipino', 'tagalog']):\n","        response = random.choice(confused_messages)\n","        interaction = {'patient':query, 'you':response}\n","        conversation_history.append(interaction)\n","        return response, status, summary, format_transcript(conversation_history)\n","    question = f\"You are Chloe, Doctor Mike's assistant interviewing a patient. {intro_intsruction} Only ask one question at a time if needed.  Ask around 5 questions then tell the patient that you will relay the information to the doctor. You can give a summary of the conversation whan asked. Do not give answers as lists, and do not use any markup. Do not use apostrpohes to shorten words. Use word representations for numbers. Do not abbreviate words. Give answers in {language}. Give a summary of the conversaion to the patient after you have asked your questions. Conversaion history is:{conversation_history} The current query is: {query}\"\n","    print(f'conversation history size={len(conversation_history)} question length={len(question)}')\n","    response = llm_chain.invoke(question).content\n","    interaction = {'patient':query, 'you':response}\n","    conversation_history.append(interaction)\n","    if len(conversation_history) > 1:\n","      summary_prompt = f'Summarize the symptoms given by the patient from this conversation in bullet points: {conversation_history}'\n","      summary = llm_chain.invoke(summary_prompt).content\n","    else:\n","      summary = 'START CONVERSATION'\n","\n","    intro_given = True\n","    intro_intsruction = ''\n","\n","    return response, status, summary, format_transcript(conversation_history)"]},{"cell_type":"markdown","metadata":{"id":"c-xcysd-NXiT"},"source":["Setup Whisper Speech To Text"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"u_-t0oqvNXiT","outputId":"4d31d513-0e63-4055-cf63-7160f89c63ba","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741025846948,"user_tz":-480,"elapsed":24858,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(fp, map_location=device)\n"]},{"output_type":"stream","name":"stdout","text":["WHISPER SAYS  Hello.\n"]}],"source":["from transformers import pipeline\n","import gradio as gr\n","import torch\n","import whisper\n","\n","if torch.cuda.is_available():\n","  device = \"cuda:0\"\n","else:\n","  device = \"cpu\"\n","print(\"Using device\", device)\n","model = whisper.load_model(\"turbo\")\n","model.to(device)\n","# wake the model up\n","\n","print(f'WHISPER SAYS {model.transcribe(f\"{data_dir}/hello.wav\")[\"text\"]}')\n","\n","# pipe = pipeline(model=model, device=device , return_timestamps=True)\n","\n","# def transcribe(audio):\n","#     if audio == None:\n","#       #  print('NO DATA')\n","#        response = 'NO DATA GIVEN'\n","#        return response\n","#     try:\n","\n","#       text = model.transcribe(audio, language=\"tl\")[\"text\"]\n","#       if len(text.strip()) > 0:\n","#         print(f'TRANSCRIBE {text}')\n","#       return text\n","#     except:\n","#        response = 'ERROR TRANSCRIBING'\n","#        return response"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"G0W7LSbvNXiV","executionInfo":{"status":"ok","timestamp":1741025846952,"user_tz":-480,"elapsed":2,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"outputs":[],"source":["\n","\n","import soundfile as sf\n","import librosa\n","\n","\n","\n","\n","\n","def transcribe(data, orig_rate):\n","    audio_array = librosa.resample(data, orig_sr=orig_rate, target_sr=16000)\n","    norm = np.linalg.norm(audio_array)\n","    if norm != 0:\n","        audio_array = audio_array / norm\n","    # sf.write('new_file.wav', audio_array, orig_rate)\n","    audio_array =  torch.from_numpy(audio_array.astype(np.float32))\n","    audio_array.to(device)\n","    # print(np.abs(data).mean())\n","    result = model.transcribe(audio_array,language=\"tl\")\n","    print(result)\n","    return result['text']\n","\n","def detect_signal(data):\n","    global talking\n","    global silence_counter\n","    global voice_data\n","    global last_query\n","    global last_response\n","    global active\n","    global inactive_timer\n","    result = None\n","\n","    silence_amplitude_threshold = 700\n","    silence_time_treshold = 3\n","    mean = np.mean(np.abs(data[1]))\n","    # print(mean)\n","    if mean > silence_amplitude_threshold:\n","        talking = True\n","        silence_counter=0\n","        voice_data = np.concatenate([voice_data,data[1]])\n","        # print(f'SAMPLE RATE={data[0]} VOICE DATA SHAPE={voice_data.shape}')\n","\n","    elif talking:\n","        silence_counter += 1\n","\n","    if silence_counter > silence_time_treshold:\n","        silence_counter = 0\n","        talking = False\n","        result = voice_data\n","        voice_data = np.array([])\n","\n","    # print(f'SILENCE {silence_counter}')\n","\n","    if type(None) != type(result):\n","        transcription = transcribe(result, data[0])\n","        if not active and transcription.lower().replace(',','').strip().startswith('hey chloe'):\n","            last_query = transcription\n","            active = True\n","            inactive_timer = datetime.now()\n","        elif active == True:\n","            inactive_timer = datetime.now()\n","            last_query = transcription\n","    else:\n","        inactive_time =  datetime.now() - inactive_timer\n","        # print(f'INACTIVE TIME {inactive_time.total_seconds()}')\n","        # if inactive_time.total_seconds() > 60:\n","        #     active = False\n","    status = 'INACTIVE! Say \"Hey, Chloe\" to wake up.'\n","    if active:\n","        status = 'ACTIVE!'\n","    return last_query, status"]},{"cell_type":"markdown","metadata":{"id":"6TzDnIWiNXiV"},"source":["Setup the Parler Text To Speech Model"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"rTPsBbkCNXiV","executionInfo":{"status":"ok","timestamp":1741025846954,"user_tz":-480,"elapsed":1,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"outputs":[],"source":["# from parler_tts import ParlerTTSStreamer\n","# from parler_tts import ParlerTTSForConditionalGeneration\n","\n","# from transformers import AutoTokenizer, AutoFeatureExtractor, set_seed\n","# import numpy as np\n","# import spaces\n","# import torch\n","# from threading import Thread\n","\n","\n","# device = \"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n","# torch_dtype = torch.float16 if device != \"cpu\" else torch.float32\n","\n","# modelid_tiny = \"parler-tts/parler-tts-tiny-v1\"\n","# print('LOADING PARLER TTS MODEL')\n","# tts_model = ParlerTTSForConditionalGeneration.from_pretrained(\n","#     modelid_tiny, torch_dtype=torch_dtype, low_cpu_mem_usage=True\n","# ).to(device)\n","\n","# tokenizer = AutoTokenizer.from_pretrained(modelid_tiny)\n","# feature_extractor = AutoFeatureExtractor.from_pretrained(modelid_tiny)\n","\n","# sampling_rate = tts_model.audio_encoder.config.sampling_rate\n","# frame_rate = tts_model.audio_encoder.config.frame_rate\n","# description = \"Jenna speaks at an average pace with a calm delivery in a very confined sounding environment with clear audio quality.\"\n","# description_tokens = tokenizer(description, return_tensors=\"pt\").to(device)\n","\n","# print('READY')\n","# SAMPLE_RATE = feature_extractor.sampling_rate\n","# SEED = 42\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"66I45vOVNXiW","executionInfo":{"status":"ok","timestamp":1741025846957,"user_tz":-480,"elapsed":2,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"outputs":[],"source":["\n","from pydub import AudioSegment\n","import io\n","import re\n","from pydub.effects import speedup\n","\n","def numpy_to_mp3(audio_array, sampling_rate):\n","    # Normalize audio_array if it's floating-point\n","    if np.issubdtype(audio_array.dtype, np.floating):\n","        max_val = np.max(np.abs(audio_array))\n","        audio_array = (audio_array / max_val) * 32767 # Normalize to 16-bit range\n","        audio_array = audio_array.astype(np.int16)\n","\n","    # Create an audio segment from the numpy array\n","    audio_segment = AudioSegment(\n","        audio_array.tobytes(),\n","        frame_rate=sampling_rate,\n","        sample_width=audio_array.dtype.itemsize,\n","        channels=1\n","    )\n","\n","    # so = audio_segment.speedup(1.25, 50, 25)\n","\n","    so = audio_segment._spawn(audio_segment.raw_data, overrides={\n","        \"frame_rate\": int(audio_segment.frame_rate * 1.25)\n","    }).set_frame_rate(audio_segment.frame_rate)\n","\n","\n","    # Export the audio segment to MP3 bytes - use a high bitrate to maximise quality\n","    mp3_io = io.BytesIO()\n","    so.export(mp3_io, format=\"mp3\", bitrate=\"320k\")\n","\n","    # Get the MP3 bytes\n","    mp3_bytes = mp3_io.getvalue()\n","    mp3_io.close()\n","\n","    return mp3_bytes\n","\n","# sampling_rate = tts_model.audio_encoder.config.sampling_rate\n","# frame_rate = tts_model.audio_encoder.config.frame_rate\n","\n","def split_text(text):\n","    text = text.replace('(','').replace(')','')\n","    phrases = re.split(r'(\\.\\s+|\\n|\\?\\s+|\\!\\s+|\\:\\s+)', text)\n","    # print(phrases)\n","    reconstructed = [ ''.join(x) for x in zip(phrases[0::2], phrases[1::2])]\n","    reconstructed.append(phrases[-1])\n","    stripped = [x.strip().replace('.','').replace('!','') for x in reconstructed if len(x.strip()) > 1]\n","    # print(reconstructed)\n","    return stripped"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"kwOb7PuNNXiW","executionInfo":{"status":"ok","timestamp":1741025846959,"user_tz":-480,"elapsed":1,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"outputs":[],"source":["# @spaces.GPU\n","# def read_response(answer):\n","#     if answer == None:\n","#         return None\n","\n","#     print(f'READING RESPONSE {answer}')\n","\n","#     play_steps_in_s = 5.0\n","#     play_steps = int(frame_rate * play_steps_in_s)\n","\n","\n","#     phrases = split_text(answer)\n","\n","#     for phrase in phrases:\n","#         streamer = ParlerTTSStreamer(tts_model, device=device, play_steps=play_steps)\n","#         prompt = tokenizer(phrase, return_tensors=\"pt\").to(device)\n","\n","#         generation_kwargs = dict(\n","#             input_ids=description_tokens.input_ids,\n","#             prompt_input_ids=prompt.input_ids,\n","#             streamer=streamer,\n","#             do_sample=True,\n","#             temperature=1.0,\n","#             min_new_tokens=20,\n","#         )\n","\n","#         set_seed(42)\n","#         thread = Thread(target=tts_model.generate, kwargs=generation_kwargs)\n","#         thread.start()\n","\n","#         for new_audio in streamer:\n","#             print(f\"Sample of length: {round(new_audio.shape[0] / sampling_rate, 2)} seconds\")\n","#             yield phrase, numpy_to_mp3(new_audio, sampling_rate=sampling_rate)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Mk7u-vesNXiX","executionInfo":{"status":"ok","timestamp":1741025846961,"user_tz":-480,"elapsed":1,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"outputs":[],"source":["from gtts import gTTS\n","from io import BytesIO\n","from pydub import AudioSegment\n","\n","def read_response_gtts(answer):\n","    if answer == None or answer=='':\n","        return None\n","    print(f'READING RESPONSE {answer}')\n","    language = 'tl'\n","\n","    phrases = split_text(answer)\n","\n","    for phrase in phrases:\n","        print(phrase)\n","        myMP3 = BytesIO()\n","        tts = gTTS(text=phrase, lang=language, slow=False)\n","        tts.write_to_fp(myMP3)\n","        myMP3.seek(0)\n","        audio = AudioSegment.from_file(io.BytesIO(myMP3.getvalue()), format=\"mp3\")\n","        # speed_up = audio._spawn(audio.raw_data, overrides={\n","        #     \"frame_rate\": int(audio.frame_rate * 1.5)\n","        # }).set_frame_rate(audio.frame_rate)\n","\n","        speed_up = audio.speedup(1.25)\n","\n","\n","        output_io = io.BytesIO()\n","        speed_up.export(output_io, format=\"mp3\")\n","        output_io.seek(0)  #\n","\n","        yield output_io.getvalue()"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"CaAk0qNVNXiX","executionInfo":{"status":"ok","timestamp":1741025846963,"user_tz":-480,"elapsed":1,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"outputs":[],"source":["def update_output():\n","    print('UPDATE')"]},{"cell_type":"code","source":["def reset_audio(input):\n","    return None, None\n",""],"metadata":{"id":"LfdMrS_UmC4C","executionInfo":{"status":"ok","timestamp":1741025846966,"user_tz":-480,"elapsed":2,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def reset():\n","  global conversation_history\n","  global intro_given\n","  global inactive_timer\n","  global talking\n","  global silence_counter\n","  global voice_data\n","  global last_query\n","  global last_response\n","  conversation_history = []\n","  intro_given = False\n","  inactive_timer = datetime.now()\n","  talking = False\n","  silence_counter = 0\n","  voice_data=np.array([])\n","  last_query = ''\n","  last_response=''\n","  last_query = 'Hello'\n","  print('RESET')\n","  return 'RESET', last_query"],"metadata":{"id":"u-z5TUcD-0mK","executionInfo":{"status":"ok","timestamp":1741025846982,"user_tz":-480,"elapsed":15,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2IAB_7IEmC2g","executionInfo":{"status":"ok","timestamp":1741025846985,"user_tz":-480,"elapsed":1,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NWSCGaugNXiX"},"source":["Launch the Web Interface"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"m7dJFBlcNXiX","outputId":"4ce944c4-c7fa-4383-8193-a40edb3da89b","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1741026205305,"user_tz":-480,"elapsed":358318,"user":{"displayName":"Andy Garcia","userId":"08903026868215047501"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://7cda23e02acecc544a.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://7cda23e02acecc544a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'text': ' Hello!', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 0.14, 'text': ' Hello!', 'tokens': [50365, 2425, 0, 50372], 'temperature': 0.0, 'avg_logprob': -0.5119153976440429, 'compression_ratio': 0.42857142857142855, 'no_speech_prob': 7.036488752776293e-11}], 'language': 'tl'}\n","LANGUAGE=English\n","conversation history size=0 question length=620\n","READING RESPONSE Hello! My name is Chloe, and I am Doctor Mike's assistant. How are you feeling today?\n","Hello\n","My name is Chloe, and I am Doctor Mike's assistant\n","How are you feeling today?\n","{'text': ' shoulders.', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 0.36, 'text': ' shoulders.', 'tokens': [50365, 10245, 13, 50383], 'temperature': 0.0, 'avg_logprob': -0.5081272602081299, 'compression_ratio': 0.5555555555555556, 'no_speech_prob': 3.5225773686864414e-11}], 'language': 'tl'}\n","LANGUAGE=English\n","conversation history size=1 question length=708\n","READING RESPONSE Could you please describe any discomfort or pain you are experiencing in your shoulders?\n","Could you please describe any discomfort or pain you are experiencing in your shoulders?\n","{'text': ' Thank you.', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 29.98, 'text': ' Thank you.', 'tokens': [50365, 1044, 291, 13, 51864], 'temperature': 0.0, 'avg_logprob': -0.42534875869750977, 'compression_ratio': 0.5555555555555556, 'no_speech_prob': 7.922171946228573e-11}], 'language': 'tl'}\n","LANGUAGE=English\n","conversation history size=2 question length=835\n","READING RESPONSE You are welcome. Could you tell me when you first noticed the discomfort in your shoulders?\n","You are welcome\n","Could you tell me when you first noticed the discomfort in your shoulders?\n","{'text': ' I noticed it around 6 days ago.', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 3.52, 'text': ' I noticed it around 6 days ago.', 'tokens': [50365, 286, 5694, 309, 926, 1386, 1708, 2057, 13, 50541], 'temperature': 0.0, 'avg_logprob': -0.19468927383422852, 'compression_ratio': 0.7948717948717948, 'no_speech_prob': 1.1057652710144694e-10}], 'language': 'tl'}\n","LANGUAGE=English\n","conversation history size=3 question length=986\n","READING RESPONSE Thank you for sharing that. Have you noticed if anything specific seems to make the discomfort in your shoulders better or worse?\n","Thank you for sharing that\n","Have you noticed if anything specific seems to make the discomfort in your shoulders better or worse?\n","{'text': \" It's always the same.\", 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 0.92, 'text': \" It's always the same.\", 'tokens': [50365, 467, 311, 1009, 264, 912, 13, 50411], 'temperature': 0.0, 'avg_logprob': -0.1671445502175225, 'compression_ratio': 0.7241379310344828, 'no_speech_prob': 1.8608597301961183e-11}], 'language': 'tl'}\n","LANGUAGE=English\n","conversation history size=4 question length=1165\n","READING RESPONSE Thank you for letting me know. Have you tried any treatments or remedies for your shoulder discomfort, and if so, have they been effective?\n","Thank you for letting me know\n","Have you tried any treatments or remedies for your shoulder discomfort, and if so, have they been effective?\n","{'text': ' I tried pain reliever, ibuprofen.', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 3.38, 'text': ' I tried pain reliever, ibuprofen.', 'tokens': [50365, 286, 3031, 1822, 21680, 331, 11, 39073, 1010, 340, 6570, 13, 50534], 'temperature': 0.0, 'avg_logprob': -0.24025213718414307, 'compression_ratio': 0.8048780487804879, 'no_speech_prob': 1.2576489849536188e-10}], 'language': 'tl'}\n","LANGUAGE=English\n","conversation history size=5 question length=1366\n","READING RESPONSE Thank you for sharing that. Have you experienced any other symptoms along with the shoulder discomfort, such as swelling, redness, or limited range of motion?\n","Thank you for sharing that\n","Have you experienced any other symptoms along with the shoulder discomfort, such as swelling, redness, or limited range of motion?\n","{'text': \" There's a little bit of swell.\", 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 1.48, 'text': \" There's a little bit of swell.\", 'tokens': [50365, 821, 311, 257, 707, 857, 295, 34251, 13, 50439], 'temperature': 0.0, 'avg_logprob': -0.17691760713403876, 'compression_ratio': 0.7894736842105263, 'no_speech_prob': 6.254503859270955e-11}], 'language': 'tl'}\n","LANGUAGE=English\n","conversation history size=6 question length=1583\n","READING RESPONSE Thank you for letting me know about the swelling. Have you had any previous injuries or conditions related to your shoulders that might be relevant? Once you provide this information, I will relay it to Doctor Mike.\n","Thank you for letting me know about the swelling\n","Have you had any previous injuries or conditions related to your shoulders that might be relevant?\n","Once you provide this information, I will relay it to Doctor Mike\n","{'text': ' Can you repeat that, please?', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 1.3, 'text': ' Can you repeat that, please?', 'tokens': [50365, 1664, 291, 7149, 300, 11, 1767, 30, 50430], 'temperature': 0.0, 'avg_logprob': -0.15274198055267335, 'compression_ratio': 0.7777777777777778, 'no_speech_prob': 1.955854575519389e-11}], 'language': 'tl'}\n","LANGUAGE=English\n","conversation history size=7 question length=1855\n","READING RESPONSE Certainly. Here is a summary of our conversation: You mentioned experiencing discomfort in your shoulders, which you first noticed around six days ago. You have tried using ibuprofen as a pain reliever. The discomfort does not seem to change with any specific activities. You also mentioned a little bit of swelling in the area. Lastly, I asked if you have had any previous injuries or conditions related to your shoulders that might be relevant. I will relay this information to Doctor Mike.\n","Certainly\n","Here is a summary of our conversation:\n","You mentioned experiencing discomfort in your shoulders, which you first noticed around six days ago\n","You have tried using ibuprofen as a pain reliever\n","The discomfort does not seem to change with any specific activities\n","You also mentioned a little bit of swelling in the area\n","Lastly, I asked if you have had any previous injuries or conditions related to your shoulders that might be relevant\n","I will relay this information to Doctor Mike\n","{'text': ' Okay, thank you.', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 1.3800000000000001, 'text': ' Okay, thank you.', 'tokens': [50365, 1033, 11, 1309, 291, 13, 50434], 'temperature': 0.0, 'avg_logprob': -0.2926437258720398, 'compression_ratio': 0.6666666666666666, 'no_speech_prob': 1.4613381685291138e-11}], 'language': 'tl'}\n","LANGUAGE=English\n","conversation history size=8 question length=2392\n","READING RESPONSE You are welcome. I will make sure to relay all the information we discussed to Doctor Mike. If you have any other questions or concerns, feel free to let us know. Take care!\n","You are welcome\n","I will make sure to relay all the information we discussed to Doctor Mike\n","If you have any other questions or concerns, feel free to let us know\n","Take care\n","Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 <> https://7cda23e02acecc544a.gradio.live\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":18}],"source":["with gr.Blocks() as block:\n","    gr.HTML(\n","        f\"\"\"\n","        <h1 style='text-align: center;'>LT5 Healthcare Assistant Chatbot</h1>\n","        <h3 style='text-align: center;'>Click on \"Record\" to start the conversation, wait 5 seconds then say Hello</h3>\n","        \"\"\"\n","    )\n","    with gr.Group():\n","        with gr.Row():\n","            reset_btn = gr.Button(\"Reset Chat Session\")\n","\n","            status = gr.Textbox(label=\"Status\")\n","            query = gr.Textbox(label=\"Query\", interactive=False)\n","            text_query = gr.Textbox(label=\"Text Query\")\n","            answer = gr.Textbox(label=\"Answer\")\n","            # state = gr.State()\n","        with gr.Row():\n","            audio_out = gr.Audio(label=\"Spoken Answer\", streaming=True, autoplay=True)\n","            audio_in = gr.Audio(label=\"Speak your question\", sources=\"microphone\", streaming=True, type=\"numpy\")\n","        with gr.Row():\n","          summary = gr.Textbox(label=\"Summary\")\n","        with gr.Row():\n","          transcript = gr.Textbox(label=\"Transcript\")\n","    audio_in.stream(detect_signal, inputs = audio_in, outputs = [query,status])\n","    text_query.submit(reset_audio,inputs=text_query, outputs=[answer, status]).then(get_response,inputs=text_query, outputs=[answer,status, summary, transcript])\n","    query.change(reset_audio,inputs=query, outputs=[answer, status]).then(get_response,inputs=query, outputs=[answer,status, summary, transcript])\n","    answer.change(read_response_gtts,inputs=answer, outputs=[audio_out])\n","    answer.submit(read_response_gtts,inputs=answer, outputs=[audio_out])\n","    reset_btn.click(fn=reset, outputs=[status,query] , api_name=\"reset\")\n","\n","\n","\n","block.launch(inbrowser=True,  share=True, debug=True)"]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.9"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}